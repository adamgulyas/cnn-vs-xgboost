{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, LSTM, TimeDistributed, Reshape\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_absolute_error\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_CUTOFF = '2020-01-31'\n",
    "TRAIN_VALID_RATIO = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric functions for calculating F-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    " \n",
    "def _precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    " \n",
    "def _f1(y_true, y_pred):\n",
    "    precision = _precision(y_true, y_pred)\n",
    "    recall = _recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    " \n",
    "def f1macro(y_true, y_pred):\n",
    "    f_pos = _f1(y_true, y_pred)\n",
    "    # negative version of the data and prediction\n",
    "    f_neg = _f1(1-y_true, 1-K.clip(y_pred,0,1))\n",
    "    return (f_pos + f_neg)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnpred_2d(seq_len=60, n_features=74, n_filters=(8,8,8), droprate=0.1):\n",
    "    \"2D-CNNpred model according to the paper\"\n",
    "    \n",
    "    # model = Sequential([\n",
    "    #     Input(shape=(seq_len, n_features, 1)),\n",
    "    #     Conv2D(n_filters[0], kernel_size=(1, n_features), activation=\"relu\"),\n",
    "    #     Conv2D(n_filters[1], kernel_size=(3,1), activation=\"relu\"),\n",
    "    #     MaxPool2D(pool_size=(2,1)),\n",
    "    #     Conv2D(n_filters[2], kernel_size=(3,1), activation=\"relu\"),\n",
    "    #     MaxPool2D(pool_size=(2,1)),\n",
    "    #     Flatten(),\n",
    "    #     Dropout(droprate),\n",
    "    #     Dense(1, activation=\"sigmoid\")\n",
    "    # ])\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(seq_len, n_features, 1)),\n",
    "        Conv2D(n_filters[0], kernel_size=(1, n_features), activation=\"relu\"),\n",
    "        Reshape((seq_len, n_features)),\n",
    "        LSTM(512),\n",
    "        LSTM(128),\n",
    "        LSTM(64),\n",
    "        TimeDistributed(Dense(512)),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(256)),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(128)),\n",
    "        TimeDistributed(Dense(64)),\n",
    "        TimeDistributed(Dense(32)),\n",
    "        TimeDistributed(Dense(16)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagen(df, seq_len, batch_size, target_col, kind):\n",
    "    \"\"\"A generator to produce samples for Keras model\"\"\"\n",
    "\n",
    "    batch = []\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Set up splitting parameters\n",
    "        input_cols = [c for c in df.columns if c != target_col]\n",
    "        index = df.index[df.index < TRAIN_TEST_CUTOFF]\n",
    "        split = int(len(index) * TRAIN_VALID_RATIO)\n",
    "\n",
    "        # Range for the training set\n",
    "        if kind == 'train':\n",
    "            index = index[:split]\n",
    "\n",
    "        # Range for the validation set\n",
    "        elif kind == 'valid':\n",
    "            index = index[split:]   \n",
    "\n",
    "        while True:\n",
    "            \"Pick one position, then clip a sequence length\"\n",
    "\n",
    "            # Pick one time step\n",
    "            t = random.choice(index)\n",
    "\n",
    "            # Find its position in the DataFrame      \n",
    "            n = (df.index == t).argmax()\n",
    "\n",
    "            # Start over if there isn't enough data for one sequence length  \n",
    "            if (n - seq_len + 1) < 0:\n",
    "                continue\n",
    "            \n",
    "            # Create the DataFrame of one sequence length\n",
    "            frame = df.iloc[n - seq_len+1 : n+1]\n",
    "\n",
    "            # Append X and y values as a sample in the CNN dataset\n",
    "            batch.append([frame[input_cols].values, df.loc[t, target_col]])\n",
    "\n",
    "            break\n",
    "\n",
    "        # If we get enough for a batch, yield the instance\n",
    "        if len(batch) == batch_size:\n",
    "\n",
    "            # Unpack the `batch` list into features and target\n",
    "            X, y = zip(*batch)\n",
    "\n",
    "            # Expand dimensions of X\n",
    "            X, y = np.expand_dims(np.array(X), 3), np.array(y)\n",
    "\n",
    "            # Yield the sample\n",
    "            yield X, y\n",
    "\n",
    "            # Clear the batch list for next iteration\n",
    "            batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testgen(df, seq_len, target_col):\n",
    "    \"Return array of all test samples\"\n",
    "\n",
    "    batch = []\n",
    "\n",
    "    input_cols = [c for c in df.columns if c != target_col]\n",
    "\n",
    "    # find the start of test sample\n",
    "    t = df.index[df.index > TRAIN_TEST_CUTOFF][0]\n",
    "    n = (df.index == t).argmax()\n",
    "\n",
    "    for i in range(n+1, len(df)+1):\n",
    "\n",
    "        frame = df.iloc[i-seq_len:i]\n",
    "        batch.append([frame[input_cols].values, frame[target_col][-1]])\n",
    "\n",
    "    X, y = zip(*batch)\n",
    "\n",
    "    return np.expand_dims(np.array(X),3), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../csv/initial_variables.csv', index_col='date', parse_dates=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data.columns\n",
    "\n",
    "# If the current price is higher than yesterday's price then target = 1, else 0\n",
    "data['target'] = (data['close'].pct_change().shift(-1) > 0).astype(int)\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Fit the standard scaler using the training dataset\n",
    "index = data.index[data.index > TRAIN_TEST_CUTOFF]\n",
    "index = index[:int(len(index) * TRAIN_VALID_RATIO)]\n",
    "scaler = StandardScaler().fit(data.loc[:, cols])\n",
    "\n",
    "# Save scale transformed dataframe\n",
    "data[cols] = scaler.transform(data[cols])\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"reshape_7\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [60, 1, 8], output_shape = [60, 74]\n\nCall arguments received by layer \"reshape_7\" (type Reshape):\n  â€¢ inputs=tf.Tensor(shape=(None, 60, 1, 8), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m n_epochs \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m n_features \u001b[39m=\u001b[39m \u001b[39m74\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m cnnpred_2d(seq_len, n_features)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m, f1macro])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "\u001b[1;32m/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb Cell 12\u001b[0m in \u001b[0;36mcnnpred_2d\u001b[0;34m(seq_len, n_features, n_filters, droprate)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m\"\u001b[39m\u001b[39m2D-CNNpred model according to the paper\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# model = Sequential([\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#     Input(shape=(seq_len, n_features, 1)),\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#     Conv2D(n_filters[0], kernel_size=(1, n_features), activation=\"relu\"),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#     Dense(1, activation=\"sigmoid\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# ])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m model \u001b[39m=\u001b[39m Sequential([\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     Input(shape\u001b[39m=\u001b[39;49m(seq_len, n_features, \u001b[39m1\u001b[39;49m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     Conv2D(n_filters[\u001b[39m0\u001b[39;49m], kernel_size\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m, n_features), activation\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     Reshape((seq_len, n_features)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     LSTM(\u001b[39m512\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     LSTM(\u001b[39m128\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     LSTM(\u001b[39m64\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     TimeDistributed(Dense(\u001b[39m512\u001b[39;49m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     Dropout(\u001b[39m0.2\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     TimeDistributed(Dense(\u001b[39m256\u001b[39;49m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     Dropout(\u001b[39m0.2\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     TimeDistributed(Dense(\u001b[39m128\u001b[39;49m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     TimeDistributed(Dense(\u001b[39m64\u001b[39;49m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     TimeDistributed(Dense(\u001b[39m32\u001b[39;49m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     TimeDistributed(Dense(\u001b[39m16\u001b[39;49m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     Dense(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adam/school/cnn-lstm/notebooks/cnn-lstm-pred.ipynb#X14sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniforge3/envs/cnn/lib/python3.10/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/cnn/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/cnn/lib/python3.10/site-packages/keras/layers/reshaping/reshape.py:111\u001b[0m, in \u001b[0;36mReshape._fix_unknown_dimension\u001b[0;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[1;32m    109\u001b[0m   output_shape[unknown] \u001b[39m=\u001b[39m original \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m known\n\u001b[1;32m    110\u001b[0m \u001b[39melif\u001b[39;00m original \u001b[39m!=\u001b[39m known:\n\u001b[0;32m--> 111\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    112\u001b[0m \u001b[39mreturn\u001b[39;00m output_shape\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape_7\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [60, 1, 8], output_shape = [60, 74]\n\nCall arguments received by layer \"reshape_7\" (type Reshape):\n  â€¢ inputs=tf.Tensor(shape=(None, 60, 1, 8), dtype=float32)"
     ]
    }
   ],
   "source": [
    "seq_len = 60\n",
    "batch_size = 128\n",
    "n_epochs = 20\n",
    "n_features = 74\n",
    " \n",
    "model = cnnpred_2d(seq_len, n_features)\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['acc', f1macro])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./models/cp2d-{epoch}-{val_f1macro:.2f}.h5\"\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor='val_f1macro', \n",
    "        mode=\"max\", verbose=0,\n",
    "        save_best_only=True, \n",
    "        save_weights_only=False, \n",
    "        save_freq=\"epoch\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "400/400 [==============================] - 30s 76ms/step - loss: 0.4506 - acc: 0.5494 - f1macro: 0.3540 - val_loss: 0.4633 - val_acc: 0.5367 - val_f1macro: 0.3485\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 31s 77ms/step - loss: 0.4567 - acc: 0.5433 - f1macro: 0.3515 - val_loss: 0.4406 - val_acc: 0.5594 - val_f1macro: 0.3583\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 31s 77ms/step - loss: 0.4505 - acc: 0.5495 - f1macro: 0.3541 - val_loss: 0.4477 - val_acc: 0.5523 - val_f1macro: 0.3554\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 30s 76ms/step - loss: 0.4539 - acc: 0.5461 - f1macro: 0.3527 - val_loss: 0.4250 - val_acc: 0.5750 - val_f1macro: 0.3644\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 30s 75ms/step - loss: 0.4564 - acc: 0.5436 - f1macro: 0.3516 - val_loss: 0.4406 - val_acc: 0.5594 - val_f1macro: 0.3584\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 31s 77ms/step - loss: 0.4560 - acc: 0.5440 - f1macro: 0.3518 - val_loss: 0.4242 - val_acc: 0.5758 - val_f1macro: 0.3648\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 30s 76ms/step - loss: 0.4494 - acc: 0.5506 - f1macro: 0.3546 - val_loss: 0.4289 - val_acc: 0.5711 - val_f1macro: 0.3632\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 30s 76ms/step - loss: 0.4529 - acc: 0.5471 - f1macro: 0.3531 - val_loss: 0.4469 - val_acc: 0.5531 - val_f1macro: 0.3557\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 31s 76ms/step - loss: 0.4520 - acc: 0.5480 - f1macro: 0.3535 - val_loss: 0.4625 - val_acc: 0.5375 - val_f1macro: 0.3493\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 31s 77ms/step - loss: 0.4521 - acc: 0.5479 - f1macro: 0.3535 - val_loss: 0.4547 - val_acc: 0.5453 - val_f1macro: 0.3523\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 30s 75ms/step - loss: 0.4557 - acc: 0.5443 - f1macro: 0.3519 - val_loss: 0.4414 - val_acc: 0.5586 - val_f1macro: 0.3578\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 30s 76ms/step - loss: 0.4556 - acc: 0.5444 - f1macro: 0.3520 - val_loss: 0.4461 - val_acc: 0.5539 - val_f1macro: 0.3561\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 30s 76ms/step - loss: 0.4540 - acc: 0.5460 - f1macro: 0.3527 - val_loss: 0.4492 - val_acc: 0.5508 - val_f1macro: 0.3546\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 30s 76ms/step - loss: 0.4510 - acc: 0.5490 - f1macro: 0.3540 - val_loss: 0.4469 - val_acc: 0.5531 - val_f1macro: 0.3556\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 31s 77ms/step - loss: 0.4533 - acc: 0.5467 - f1macro: 0.3530 - val_loss: 0.4547 - val_acc: 0.5453 - val_f1macro: 0.3523\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 30s 76ms/step - loss: 0.4492 - acc: 0.5508 - f1macro: 0.3547 - val_loss: 0.4211 - val_acc: 0.5789 - val_f1macro: 0.3664\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 30s 76ms/step - loss: 0.4544 - acc: 0.5456 - f1macro: 0.3524 - val_loss: 0.4258 - val_acc: 0.5742 - val_f1macro: 0.3644\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 29s 74ms/step - loss: 0.4511 - acc: 0.5489 - f1macro: 0.3538 - val_loss: 0.4250 - val_acc: 0.5750 - val_f1macro: 0.3648\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 30s 74ms/step - loss: 0.4539 - acc: 0.5461 - f1macro: 0.3527 - val_loss: 0.4586 - val_acc: 0.5414 - val_f1macro: 0.3508\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 30s 75ms/step - loss: 0.4587 - acc: 0.5413 - f1macro: 0.3507 - val_loss: 0.4352 - val_acc: 0.5648 - val_f1macro: 0.3605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e3954550>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_gen = datagen(data, seq_len, batch_size, 'target', 'train')\n",
    "validation_gen = datagen(data, seq_len, batch_size, 'target', 'valid')\n",
    "\n",
    "model.fit(\n",
    "    training_gen,\n",
    "    validation_data=validation_gen,\n",
    "    epochs=n_epochs, \n",
    "    steps_per_epoch=400, \n",
    "    validation_steps=10, \n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "test_data, test_target = testgen(data, seq_len, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 3ms/step\n",
      "accuracy: 0.5421303656597775\n",
      "MAE: 0.4578696343402226\n",
      "F1: 0.7030927835051547\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_out = model.predict(test_data)\n",
    "test_pred = (test_out > 0.5).astype(int)\n",
    "print('accuracy:', accuracy_score(test_pred, test_target))\n",
    "print('MAE:', mean_absolute_error(test_pred, test_target))\n",
    "print('F1:', f1_score(test_pred, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/final_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('cnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e134d545e645ca52080ee6eed13987f7920fe874666f42bfb56f6a4194d5976"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
